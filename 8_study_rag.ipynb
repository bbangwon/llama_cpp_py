{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff21d402",
   "metadata": {},
   "source": [
    "# 시멘틱 검색과 RAG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632964e1",
   "metadata": {},
   "source": [
    "## 시멘틱 검색과 RAG 소개\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b7be8a",
   "metadata": {},
   "source": [
    "- 밀집검색\n",
    "  - 밀집 검색 시스템은 임베딩 개념을 사용하여 검색 문제를 검색 쿼리의 최근접 이웃을 찾는 것으로 변환합니다.\n",
    "  - 텍스트 임베딩의 유사도를 기반으로 관련된 결과를 추출합니다.\n",
    "- 리랭킹\n",
    "  - 검색 시스템은 여러 단계로 구성된 파이프라인일 경우가 많습니다. 이런 단계 중 하나이며 쿼리와 결과의 관련성을 점수화합니다.\n",
    "  - 검색 쿼리와 검색 결과를 받아 관련성에 따라 순위를 조정합니다.\n",
    "- RAG\n",
    "  - 검색 기능을 통합하여 환각을 줄이며 사실성을 높이고 생성모델을 특정 데이터셋에 접목한 텍스트 생성 시스템입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6932404",
   "metadata": {},
   "source": [
    "## 언어 모델을 사용한 시멘틱 검색\n",
    "\n",
    "### 밀집검색\n",
    "\n",
    "- 임베딩은 텍스트를 수치 표현으로 바꾸며, 어떤 공간 위에 놓인 한 점으로 생각할수 있습니다.\n",
    "- 비슷한 의미의 텍스트는 서로 가까이 놓입니다.\n",
    "- 사용자가 입력한 검색 쿼리를 임베딩하고 텍스트 아카이브와 동일한 공간(차원이 동일한 벡터를 만든다는 의미)에 투영합니다.\n",
    "- 그다음 이 공간상에서 쿼리에 가장 가까운 문서를 찾습니다.\n",
    "- 나온 거리에서 약간 멀리 떨어진 텍스트도 반환해야 할까요?\n",
    "  - 이 결정은 시스템 설계자에게 달려 있습니다.\n",
    "  - 유사도 점수에 임곗값을 설정해 관련 없는 결과를 제외하는 것이 낫습니다.\n",
    "- 쿼리와 가장 가까운 텍스트가 의미적으로 비슷한가요?\n",
    "  - 항상 그렇지는 않습니다. 이 때문에 언어 모델을 질문-답변 쌍에서 훈련하여 검색 성능을 높여야 합니다.\n",
    "- 외부 지식 데이터를 벡터 데이터베이스로 변환합니다. 그 다음 이 벡터 데이터베이스에 쿼리하여 지식정보를 검색합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c2b34",
   "metadata": {},
   "source": [
    "- 밀집 검색 예제\n",
    "- 코히어를 사용해 위키백과에 있는 인터스텔라 영화 페이지에 담긴 내용을 검색하는 밀집 검색 예제를 만들어 보겠습니다.\n",
    "  - 간단한 처리과정을 통해 검색 대상 텍스트를 문장으로 나눕니다.\n",
    "  - 문장을 임베딩합니다.\n",
    "  - 검색 인덱스를 구축합니다.\n",
    "  - 검색을 수행하고 결과를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f346c675",
   "metadata": {},
   "source": [
    "- 코히어(https://cohere.com)에 가입하고 발급받은 API 키를 다음 코드에 붙여 넣어야 합니다.\n",
    "- 코히어는 시험용 키를 일정 한도 내에서 무료로 제공합니다.\n",
    "- 먼저 필요한 라이브러리를 임포트합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437c2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 코히어 API 키 설정\n",
    "api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c063c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코히어 클라이언트를 만듭니다.\n",
    "co = cohere.ClientV2(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d50b5",
   "metadata": {},
   "source": [
    "- 텍스트 문서 분할하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a155f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['인터스텔라는 크리스토퍼 놀란이 감독하고 그의 형제인 조너선 놀란과 공동으로 각본을 쓴 2014년의 대작 SF 영화입니다',\n",
       " '매튜 맥코너히, 앤 해서웨이, 제시카 채스테인, 빌 어윈, 엘렌 버스틴, 마이클 케인 등 앙상블 캐스트가 출연합니다',\n",
       " '지구가 재앙적인 병충해와 기근으로 고통받는 디스토피아적 미래를 배경으로, 인류를 위한 새로운 보금자리를 찾아 우주를 여행하는 우주 비행사들의 이야기를 담고 있습니다',\n",
       " '이 영화의 시나리오는 조너선이 2007년에 개발한 각본에서 시작되었으며, 원래 스티븐 스필버그가 감독을 맡을 예정이었습니다',\n",
       " '이론 물리학자 킵 손은 이 영화의 총괄 프로듀서이자 과학 자문으로 참여했으며, 관련 서적인 《인터스텔라의 과학》을 집필했습니다',\n",
       " '이 영화는 린다 옵스트가 사망하기 전 프로듀서로서 참여한 마지막 작품입니다',\n",
       " '촬영 감독 호이트 반 호이테마는 \\u200b\\u200b파나비전 아나모픽 포맷의 35mm 필름과 IMAX 70mm 필름으로 촬영했습니다',\n",
       " '촬영은 2013년 말에 시작되어 앨버타, 클라우스터, 로스앤젤레스에서 진행되었습니다',\n",
       " '《인터스텔라》는 광범위한 특수 효과와 미니어처 효과를 사용했으며, DNEG 사가 추가적인 시각 효과를 제작했습니다',\n",
       " '영화 인터스텔라는 2014년 10월 26일 TCL 차이니즈 극장에서 시사회를 가진 후, 11월 5일 미국에서, 11월 7일 영국에서 극장 개봉했습니다',\n",
       " '미국 배급은 파라마운트 픽처스가, 해외 배급은 워너 브라더스 픽처스가 맡았습니다',\n",
       " '미국에서는 처음에는 필름으로 개봉되었고, 이후 디지털 영사기를 사용하는 극장으로 확대 상영되었습니다',\n",
       " '이 영화는 상업적으로 큰 성공을 거두어 개봉 첫 주에 전 세계적으로 6억 8100만 달러의 수익을 올렸고, 이후 재개봉을 통해 7억 7380만 달러를 추가로 벌어들이며 2014년 최고 흥행작 10위에 올랐습니다',\n",
       " '평론가들로부터 대체적으로 호평을 받았습니다',\n",
       " '인터스텔라는 여러 상을 수상했는데, 특히 제 87회 아카데미 시상식에서 5개 부문 후보에 올라 시각 효과상을 수상했습니다',\n",
       " '']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "인터스텔라는 크리스토퍼 놀란이 감독하고 그의 형제인 조너선 놀란과 공동으로 각본을 쓴 2014년의 대작 SF 영화입니다. \n",
    "매튜 맥코너히, 앤 해서웨이, 제시카 채스테인, 빌 어윈, 엘렌 버스틴, 마이클 케인 등 앙상블 캐스트가 출연합니다. \n",
    "지구가 재앙적인 병충해와 기근으로 고통받는 디스토피아적 미래를 배경으로, 인류를 위한 새로운 보금자리를 찾아 우주를 여행하는 우주 비행사들의 이야기를 담고 있습니다.\n",
    "\n",
    "이 영화의 시나리오는 조너선이 2007년에 개발한 각본에서 시작되었으며, 원래 스티븐 스필버그가 감독을 맡을 예정이었습니다. \n",
    "이론 물리학자 킵 손은 이 영화의 총괄 프로듀서이자 과학 자문으로 참여했으며, 관련 서적인 《인터스텔라의 과학》을 집필했습니다. \n",
    "이 영화는 린다 옵스트가 사망하기 전 프로듀서로서 참여한 마지막 작품입니다. \n",
    "촬영 감독 호이트 반 호이테마는 ​​파나비전 아나모픽 포맷의 35mm 필름과 IMAX 70mm 필름으로 촬영했습니다. \n",
    "촬영은 2013년 말에 시작되어 앨버타, 클라우스터, 로스앤젤레스에서 진행되었습니다. \n",
    "《인터스텔라》는 광범위한 특수 효과와 미니어처 효과를 사용했으며, DNEG 사가 추가적인 시각 효과를 제작했습니다.\n",
    "\n",
    "영화 인터스텔라는 2014년 10월 26일 TCL 차이니즈 극장에서 시사회를 가진 후, 11월 5일 미국에서, 11월 7일 영국에서 극장 개봉했습니다. \n",
    "미국 배급은 파라마운트 픽처스가, 해외 배급은 워너 브라더스 픽처스가 맡았습니다. \n",
    "미국에서는 처음에는 필름으로 개봉되었고, 이후 디지털 영사기를 사용하는 극장으로 확대 상영되었습니다. \n",
    "이 영화는 상업적으로 큰 성공을 거두어 개봉 첫 주에 전 세계적으로 6억 8100만 달러의 수익을 올렸고, 이후 재개봉을 통해 7억 7380만 달러를 추가로 벌어들이며 2014년 최고 흥행작 10위에 올랐습니다. \n",
    "평론가들로부터 대체적으로 호평을 받았습니다. \n",
    "인터스텔라는 여러 상을 수상했는데, 특히 제 87회 아카데미 시상식에서 5개 부문 후보에 올라 시각 효과상을 수상했습니다.\n",
    "\"\"\"\n",
    "\n",
    "# 문장을 나누어 리스트로 만듭니다.\n",
    "texts = text.split(\".\")\n",
    "\n",
    "# 공백과 줄바꿈 문자를 삭제합니다.\n",
    "texts = [t.strip(\" \\n\") for t in texts]\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcfc014",
   "metadata": {},
   "source": [
    "- 문장 임베딩하기\n",
    "- 문장 리스트를 코히어 API에 전송하여 각 텍스트에 대한 벡터를 얻습니다.\n",
    "- 코히어 클라이언트의 embed 메서드는 최적의 임베딩을 위해 input_type 매개변수에 입력의 종류를 지정해야 합니다.\n",
    "  - 시멘틱 검색의 경우 쿼리는 \"search_query\"로, 검색 대상 텍스트는 \"search_document\"로 지정해야 합니다.\n",
    "  - 분류나 클러스터링의 경우 각각 \"classification\"과 \"clustering\"으로 지정해야 합니다.\n",
    "  - 이미지를 임베딩하는 경우 \"image\"로 지정해야 합니다.\n",
    "  - embed 메서드가 반환하는 객체의 embeddings 속성은 texts 매개변수에 전달한 텍스트에 대한 임베딩을 저장한 리스트입니다.\n",
    "- embed 메서드의 model 매개변수에 임베딩에 사용할 모델을 지정할 수 있습니다.\n",
    "  - 사용 가능한 전체 모델은 코히어 온라인 문서를 참고하세요\n",
    "  - https://docs.cohere.com/reference/embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6e7bdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1536)\n"
     ]
    }
   ],
   "source": [
    "# 임베딩을 만듭니다.\n",
    "response = co.embed(\n",
    "    texts=texts,\n",
    "    model=\"embed-v4.0\",\n",
    "    input_type=\"search_document\",\n",
    "    embedding_types=[\"float\"],\n",
    ").embeddings\n",
    "\n",
    "embeds = np.array(response.float_)\n",
    "print(embeds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d204157f",
   "metadata": {},
   "source": [
    "- 크기가 1536인 벡터가 16개 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c787c3e",
   "metadata": {},
   "source": [
    "- 검색하기 전 검색 인덱스를 구축해야 합니다.\n",
    "- 검색 인덱스는 임베딩을 저장하며 많은 데이터 포인트에서도 빠르게 최근접 이웃을 검색할 수 있도록 최적화되었습니다.\n",
    "- FAISS는 페이스북에서 만든 벡터 유사도 기반 검색 라이브러리입니다.\n",
    "  - https://github.com/facebookresearch/faiss\n",
    "  - IndexFlatL2 클래스는 유클리드 거리 기반으로 최근접 이웃을 찾는 기본적인 인덱스를 생성합니다.\n",
    "  - 벡터를 추가하는 add() 메서드와 벡터를 검색하는 search() 메서드는 모두 32비트 부동소수점 실수를 기대합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd360759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "dim = embeds.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(np.float32(embeds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138365d0",
   "metadata": {},
   "source": [
    "- 인덱스 검색하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ba131af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, number_of_results=3):\n",
    "    # 쿼리 임베딩을 만듭니다.\n",
    "    query_embed = co.embed(\n",
    "        texts=[query],\n",
    "        model=\"embed-v4.0\",\n",
    "        input_type=\"search_query\",\n",
    "        embedding_types=[\"float\"],\n",
    "    ).embeddings.float_[0]\n",
    "\n",
    "    # 최근접 이웃을 추출합니다.\n",
    "    distances, similar_item_ids = index.search(\n",
    "        np.float32([query_embed]), number_of_results\n",
    "    )\n",
    "\n",
    "    # 데이터프레임을 사용해 출력을 준비합니다.\n",
    "    texts_np = np.array(\n",
    "        texts\n",
    "    )  # 인덱싱을 쉽게 하기 위해 텍스트 리스트를 넘파이 배열로 변환합니다.\n",
    "    results = pd.DataFrame(\n",
    "        data={\"텍스트\": texts_np[similar_item_ids[0]], \"거리\": distances[0]}\n",
    "    )\n",
    "\n",
    "    # 결과를 출력하고 반환합니다.\n",
    "    print(f\"쿼리: '{query}'\\n최근접 이웃:\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16c7131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: '영화를 어디서 볼 수 있나요?'\n",
      "최근접 이웃:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>텍스트</th>\n",
       "      <th>거리</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>영화 인터스텔라는 2014년 10월 26일 TCL 차이니즈 극장에서 시사회를 가진 ...</td>\n",
       "      <td>1.025083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>미국에서는 처음에는 필름으로 개봉되었고, 이후 디지털 영사기를 사용하는 극장으로 확...</td>\n",
       "      <td>1.089149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이 영화는 상업적으로 큰 성공을 거두어 개봉 첫 주에 전 세계적으로 6억 8100만...</td>\n",
       "      <td>1.241750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 텍스트        거리\n",
       "0  영화 인터스텔라는 2014년 10월 26일 TCL 차이니즈 극장에서 시사회를 가진 ...  1.025083\n",
       "1  미국에서는 처음에는 필름으로 개봉되었고, 이후 디지털 영사기를 사용하는 극장으로 확...  1.089149\n",
       "2  이 영화는 상업적으로 큰 성공을 거두어 개봉 첫 주에 전 세계적으로 6억 8100만...  1.241750"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"영화를 어디서 볼 수 있나요?\"\n",
    "results = search(query)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24079316",
   "metadata": {},
   "source": [
    "- 키워드 검색 함수를 정의해 확인할 수 있습니다.\n",
    "- 대표적인 어휘 검색 방법인 BM25 알고리즘을 사용하겠습니다.\n",
    "- 코히어 가이드 노트북 : https://github.com/cohere-ai/cohere-developer-experience/blob/main/notebooks/guides/rerank-demo.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aee6b774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질의어 토큰: ['맛있', '사과', '여행']\n",
      "\n",
      "문서 1: 맛있는 사과가 나무에 열려 있습니다.\n",
      "BM25 점수: 5.4558\n",
      "------------------------------\n",
      "문서 2: 기차를 타고 서울에서 부산까지 여행을 갑니다.\n",
      "BM25 점수: 4.9186\n",
      "------------------------------\n",
      "문서 3: 사과 나무 아래에서 기차 소리를 듣습니다.\n",
      "BM25 점수: 4.3583\n",
      "------------------------------\n",
      "문서 4: 오늘 점심은 맛있는 비빔밥을 먹었습니다.\n",
      "BM25 점수: 4.3583\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantization is not supported for ArchType::neon. Fall back to non-quantized model.\n"
     ]
    }
   ],
   "source": [
    "# 한글 BM25 알고리즘을 사용한 키워드 검색 예제\n",
    "\n",
    "from kiwipiepy import Kiwi\n",
    "from rank_bm25 import BM25Plus  # Okapi 대신 Plus 사용 (문서양이 적을 경우 사용)\n",
    "\n",
    "kiwi = Kiwi()\n",
    "\n",
    "\n",
    "# 2. 형태소 분석 함수 정의 (명사, 동사, 형용사 등 의미 있는 품사만 추출)\n",
    "def tokenize_korean(text):\n",
    "    # Kiwi를 통해 형태소 분석\n",
    "    tokens = kiwi.tokenize(text)\n",
    "    # 일반명사(NNG), 고유명사(NNP), 동사(VV), 형용사(VA) 등 주요 키워드만 필터링\n",
    "    return [t.form for t in tokens if t.tag in [\"NNG\", \"NNP\", \"VV\", \"VA\"]]\n",
    "\n",
    "\n",
    "corpus = [\n",
    "    \"맛있는 사과가 나무에 열려 있습니다.\",\n",
    "    \"기차를 타고 서울에서 부산까지 여행을 갑니다.\",\n",
    "    \"사과 나무 아래에서 기차 소리를 듣습니다.\",\n",
    "    \"오늘 점심은 맛있는 비빔밥을 먹었습니다.\",\n",
    "]\n",
    "\n",
    "tokenized_corpus = [tokenize_korean(doc) for doc in corpus]\n",
    "\n",
    "# BM25Plus 모델 사용\n",
    "bm25 = BM25Plus(tokenized_corpus)\n",
    "\n",
    "query = \"맛있는 사과 여행\"\n",
    "tokenized_query = tokenize_korean(query)\n",
    "\n",
    "doc_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "print(f\"질의어 토큰: {tokenized_query}\\n\")\n",
    "for i, score in enumerate(doc_scores):\n",
    "    print(f\"문서 {i + 1}: {corpus[i]}\")\n",
    "    print(f\"BM25 점수: {score:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d12aabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantization is not supported for ArchType::neon. Fall back to non-quantized model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질의어: 맛있는 사과 여행\n",
      "------------------------------\n",
      "문서 1: 맛있는 사과가 나무에 열려 있습니다.\n",
      "BM25 점수: 0.0000\n",
      "------------------------------\n",
      "문서 2: 기차를 타고 서울에서 부산까지 여행을 갑니다.\n",
      "BM25 점수: 0.7773\n",
      "------------------------------\n",
      "문서 3: 사과 나무 아래에서 기차 소리를 듣습니다.\n",
      "BM25 점수: 0.0000\n",
      "------------------------------\n",
      "문서 4: 오늘 점심은 맛있는 비빔밥을 먹었습니다.\n",
      "BM25 점수: 0.0000\n",
      "------------------------------\n",
      "최종 추천 문서: 기차를 타고 서울에서 부산까지 여행을 갑니다.\n"
     ]
    }
   ],
   "source": [
    "# 문서양이 많을 때는 이것을 사용해도 됨\n",
    "\n",
    "from kiwipiepy import Kiwi\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# 1. Kiwi 초기화\n",
    "kiwi = Kiwi()\n",
    "\n",
    "\n",
    "# 2. 형태소 분석 함수 정의 (명사, 동사, 형용사 등 의미 있는 품사만 추출)\n",
    "def tokenize_korean(text):\n",
    "    # Kiwi를 통해 형태소 분석\n",
    "    tokens = kiwi.tokenize(text)\n",
    "    # 일반명사(NNG), 고유명사(NNP), 동사(VV), 형용사(VA) 등 주요 키워드만 필터링\n",
    "    return [t.form for t in tokens if t.tag in [\"NNG\", \"NNP\", \"VV\", \"VA\"]]\n",
    "\n",
    "\n",
    "# 3. 샘플 데이터 (문서 리스트)\n",
    "corpus = [\n",
    "    \"맛있는 사과가 나무에 열려 있습니다.\",\n",
    "    \"기차를 타고 서울에서 부산까지 여행을 갑니다.\",\n",
    "    \"사과 나무 아래에서 기차 소리를 듣습니다.\",\n",
    "    \"오늘 점심은 맛있는 비빔밥을 먹었습니다.\",\n",
    "]\n",
    "\n",
    "# 4. 문서 토큰화\n",
    "tokenized_corpus = [tokenize_korean(doc) for doc in corpus]\n",
    "\n",
    "# 5. BM25 모델 생성\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# 6. 질의어 설정 및 분석\n",
    "query = \"맛있는 사과 여행\"\n",
    "tokenized_query = tokenize_korean(query)\n",
    "\n",
    "# 7. 점수 계산 및 결과 출력\n",
    "doc_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "print(f\"질의어: {query}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for i, score in enumerate(doc_scores):\n",
    "    print(f\"문서 {i + 1}: {corpus[i]}\")\n",
    "    print(f\"BM25 점수: {score:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# 가장 점수가 높은 문서 추출\n",
    "top_n = bm25.get_top_n(tokenized_query, corpus, n=1)\n",
    "print(f\"최종 추천 문서: {top_n[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9679facc",
   "metadata": {},
   "source": [
    "- BM25는 TF-IDF 알고리즘을 개선한 텍스트 랭킹 및 검색 알고리즘입니다.\n",
    "- BM250kapi 클래스에 각 문서를 토큰으로 분할한 리스트를 전달한 후 get_scores() 메서드를 사용해 쿼리와의 유사도 점수를 얻습니다.\n",
    "- https://en.wikipedia.org/wiki/Okapi_BM25\n",
    "- https://github.com/dorianbrown/rank_bm25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요건 영어 일때..\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import string\n",
    "\n",
    "\n",
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.lower().split():\n",
    "        token = token.strip(string.punctuation)  # 구두점 제거\n",
    "        if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
    "            tokenized_doc.append(token)\n",
    "    return tokenized_doc\n",
    "\n",
    "\n",
    "tokenized_corpus = []\n",
    "for passage in tqdm(texts):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "\n",
    "def keyword_search(query, top_k=3, num_candidates=15):\n",
    "    print(\"입력 질문:\", query)\n",
    "\n",
    "    ##### BM25 검색 (어휘 검색) #####\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{\"corpus_id\": idx, \"score\": bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    print(\"탑-3 어휘 검색 (BM25) 결과\")\n",
    "    for hit in bm25_hits[:top_k]:\n",
    "        print(\n",
    "            \"\\t{:.3f}\\t{}\".format(\n",
    "                hit[\"score\"], texts[hit[\"corpus_id\"]].replace(\"\\n\", \" \")\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1241ce49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 1571.89it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus = []\n",
    "for passage in tqdm(texts):\n",
    "    tokenized_corpus.append(tokenize_korean(passage))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "\n",
    "def keyword_search(query, top_k=3, num_candidates=15):\n",
    "    print(\"입력 질문:\", query)\n",
    "\n",
    "    ##### BM25 검색 (어휘 검색) #####\n",
    "    bm25_scores = bm25.get_scores(tokenize_korean(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{\"corpus_id\": idx, \"score\": bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    print(\"탑-3 어휘 검색 (BM25) 결과\")\n",
    "    for hit in bm25_hits[:top_k]:\n",
    "        print(\n",
    "            \"\\t{:.3f}\\t{}\".format(\n",
    "                hit[\"score\"], texts[hit[\"corpus_id\"]].replace(\"\\n\", \" \")\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d5cf331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 질문: 영화를 어디서 볼 수 있나요?\n",
      "탑-3 어휘 검색 (BM25) 결과\n",
      "\t0.511\t이 영화는 린다 옵스트가 사망하기 전 프로듀서로서 참여한 마지막 작품입니다\n",
      "\t0.468\t인터스텔라는 크리스토퍼 놀란이 감독하고 그의 형제인 조너선 놀란과 공동으로 각본을 쓴 2014년의 대작 SF 영화입니다\n",
      "\t0.449\t이 영화의 시나리오는 조너선이 2007년에 개발한 각본에서 시작되었으며, 원래 스티븐 스필버그가 감독을 맡을 예정이었습니다\n"
     ]
    }
   ],
   "source": [
    "keyword_search(\"영화를 어디서 볼 수 있나요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3fb1bf",
   "metadata": {},
   "source": [
    "- 쿼리에 있는 영화가 포함되었지만 질문에 대한 답이 아닙니다.\n",
    "- 리랭커를 추가하여 검색 시스템을 어떻게 개선할 수 있는지 알아보겠습니다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_cpp_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

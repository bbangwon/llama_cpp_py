{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff21d402",
   "metadata": {},
   "source": [
    "# 시멘틱 검색과 RAG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632964e1",
   "metadata": {},
   "source": [
    "## 시멘틱 검색과 RAG 소개\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b7be8a",
   "metadata": {},
   "source": [
    "- 밀집검색\n",
    "  - 밀집 검색 시스템은 임베딩 개념을 사용하여 검색 문제를 검색 쿼리의 최근접 이웃을 찾는 것으로 변환합니다.\n",
    "  - 텍스트 임베딩의 유사도를 기반으로 관련된 결과를 추출합니다.\n",
    "- 리랭킹\n",
    "  - 검색 시스템은 여러 단계로 구성된 파이프라인일 경우가 많습니다. 이런 단계 중 하나이며 쿼리와 결과의 관련성을 점수화합니다.\n",
    "  - 검색 쿼리와 검색 결과를 받아 관련성에 따라 순위를 조정합니다.\n",
    "- RAG\n",
    "  - 검색 기능을 통합하여 환각을 줄이며 사실성을 높이고 생성모델을 특정 데이터셋에 접목한 텍스트 생성 시스템입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6932404",
   "metadata": {},
   "source": [
    "## 언어 모델을 사용한 시멘틱 검색\n",
    "\n",
    "### 밀집검색\n",
    "\n",
    "- 임베딩은 텍스트를 수치 표현으로 바꾸며, 어떤 공간 위에 놓인 한 점으로 생각할수 있습니다.\n",
    "- 비슷한 의미의 텍스트는 서로 가까이 놓입니다.\n",
    "- 사용자가 입력한 검색 쿼리를 임베딩하고 텍스트 아카이브와 동일한 공간(차원이 동일한 벡터를 만든다는 의미)에 투영합니다.\n",
    "- 그다음 이 공간상에서 쿼리에 가장 가까운 문서를 찾습니다.\n",
    "- 나온 거리에서 약간 멀리 떨어진 텍스트도 반환해야 할까요?\n",
    "  - 이 결정은 시스템 설계자에게 달려 있습니다.\n",
    "  - 유사도 점수에 임곗값을 설정해 관련 없는 결과를 제외하는 것이 낫습니다.\n",
    "- 쿼리와 가장 가까운 텍스트가 의미적으로 비슷한가요?\n",
    "  - 항상 그렇지는 않습니다. 이 때문에 언어 모델을 질문-답변 쌍에서 훈련하여 검색 성능을 높여야 합니다.\n",
    "- 외부 지식 데이터를 벡터 데이터베이스로 변환합니다. 그 다음 이 벡터 데이터베이스에 쿼리하여 지식정보를 검색합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c2b34",
   "metadata": {},
   "source": [
    "- 밀집 검색 예제\n",
    "- 코히어를 사용해 위키백과에 있는 인터스텔라 영화 페이지에 담긴 내용을 검색하는 밀집 검색 예제를 만들어 보겠습니다.\n",
    "  - 간단한 처리과정을 통해 검색 대상 텍스트를 문장으로 나눕니다.\n",
    "  - 문장을 임베딩합니다.\n",
    "  - 검색 인덱스를 구축합니다.\n",
    "  - 검색을 수행하고 결과를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f346c675",
   "metadata": {},
   "source": [
    "- 코히어(https://cohere.com)에 가입하고 발급받은 API 키를 다음 코드에 붙여 넣어야 합니다.\n",
    "- 코히어는 시험용 키를 일정 한도 내에서 무료로 제공합니다.\n",
    "- 먼저 필요한 라이브러리를 임포트합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437c2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 코히어 API 키 설정\n",
    "api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c063c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코히어 클라이언트를 만듭니다.\n",
    "co = cohere.ClientV2(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d50b5",
   "metadata": {},
   "source": [
    "- 텍스트 문서 분할하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57a155f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['인터스텔라는 크리스토퍼 놀란이 감독하고 그의 형제인 조너선 놀란과 공동으로 각본을 쓴 2014년의 대작 SF 영화입니다',\n",
       " '매튜 맥코너히, 앤 해서웨이, 제시카 채스테인, 빌 어윈, 엘렌 버스틴, 마이클 케인 등 앙상블 캐스트가 출연합니다',\n",
       " '지구가 재앙적인 병충해와 기근으로 고통받는 디스토피아적 미래를 배경으로, 인류를 위한 새로운 보금자리를 찾아 우주를 여행하는 우주 비행사들의 이야기를 담고 있습니다',\n",
       " '이 영화의 시나리오는 조너선이 2007년에 개발한 각본에서 시작되었으며, 원래 스티븐 스필버그가 감독을 맡을 예정이었습니다',\n",
       " '이론 물리학자 킵 손은 이 영화의 총괄 프로듀서이자 과학 자문으로 참여했으며, 관련 서적인 《인터스텔라의 과학》을 집필했습니다',\n",
       " '이 영화는 린다 옵스트가 사망하기 전 프로듀서로서 참여한 마지막 작품입니다',\n",
       " '촬영 감독 호이트 반 호이테마는 \\u200b\\u200b파나비전 아나모픽 포맷의 35mm 필름과 IMAX 70mm 필름으로 촬영했습니다',\n",
       " '촬영은 2013년 말에 시작되어 앨버타, 클라우스터, 로스앤젤레스에서 진행되었습니다',\n",
       " '《인터스텔라》는 광범위한 특수 효과와 미니어처 효과를 사용했으며, DNEG 사가 추가적인 시각 효과를 제작했습니다',\n",
       " '영화 인터스텔라는 2014년 10월 26일 TCL 차이니즈 극장에서 시사회를 가진 후, 11월 5일 미국에서, 11월 7일 영국에서 극장 개봉했습니다',\n",
       " '미국 배급은 파라마운트 픽처스가, 해외 배급은 워너 브라더스 픽처스가 맡았습니다',\n",
       " '미국에서는 처음에는 필름으로 개봉되었고, 이후 디지털 영사기를 사용하는 극장으로 확대 상영되었습니다',\n",
       " '이 영화는 상업적으로 큰 성공을 거두어 개봉 첫 주에 전 세계적으로 6억 8100만 달러의 수익을 올렸고, 이후 재개봉을 통해 7억 7380만 달러를 추가로 벌어들이며 2014년 최고 흥행작 10위에 올랐습니다',\n",
       " '평론가들로부터 대체적으로 호평을 받았습니다',\n",
       " '인터스텔라는 여러 상을 수상했는데, 특히 제 87회 아카데미 시상식에서 5개 부문 후보에 올라 시각 효과상을 수상했습니다',\n",
       " '']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "인터스텔라는 크리스토퍼 놀란이 감독하고 그의 형제인 조너선 놀란과 공동으로 각본을 쓴 2014년의 대작 SF 영화입니다. \n",
    "매튜 맥코너히, 앤 해서웨이, 제시카 채스테인, 빌 어윈, 엘렌 버스틴, 마이클 케인 등 앙상블 캐스트가 출연합니다. \n",
    "지구가 재앙적인 병충해와 기근으로 고통받는 디스토피아적 미래를 배경으로, 인류를 위한 새로운 보금자리를 찾아 우주를 여행하는 우주 비행사들의 이야기를 담고 있습니다.\n",
    "\n",
    "이 영화의 시나리오는 조너선이 2007년에 개발한 각본에서 시작되었으며, 원래 스티븐 스필버그가 감독을 맡을 예정이었습니다. \n",
    "이론 물리학자 킵 손은 이 영화의 총괄 프로듀서이자 과학 자문으로 참여했으며, 관련 서적인 《인터스텔라의 과학》을 집필했습니다. \n",
    "이 영화는 린다 옵스트가 사망하기 전 프로듀서로서 참여한 마지막 작품입니다. \n",
    "촬영 감독 호이트 반 호이테마는 ​​파나비전 아나모픽 포맷의 35mm 필름과 IMAX 70mm 필름으로 촬영했습니다. \n",
    "촬영은 2013년 말에 시작되어 앨버타, 클라우스터, 로스앤젤레스에서 진행되었습니다. \n",
    "《인터스텔라》는 광범위한 특수 효과와 미니어처 효과를 사용했으며, DNEG 사가 추가적인 시각 효과를 제작했습니다.\n",
    "\n",
    "영화 인터스텔라는 2014년 10월 26일 TCL 차이니즈 극장에서 시사회를 가진 후, 11월 5일 미국에서, 11월 7일 영국에서 극장 개봉했습니다. \n",
    "미국 배급은 파라마운트 픽처스가, 해외 배급은 워너 브라더스 픽처스가 맡았습니다. \n",
    "미국에서는 처음에는 필름으로 개봉되었고, 이후 디지털 영사기를 사용하는 극장으로 확대 상영되었습니다. \n",
    "이 영화는 상업적으로 큰 성공을 거두어 개봉 첫 주에 전 세계적으로 6억 8100만 달러의 수익을 올렸고, 이후 재개봉을 통해 7억 7380만 달러를 추가로 벌어들이며 2014년 최고 흥행작 10위에 올랐습니다. \n",
    "평론가들로부터 대체적으로 호평을 받았습니다. \n",
    "인터스텔라는 여러 상을 수상했는데, 특히 제 87회 아카데미 시상식에서 5개 부문 후보에 올라 시각 효과상을 수상했습니다.\n",
    "\"\"\"\n",
    "\n",
    "# 문장을 나누어 리스트로 만듭니다.\n",
    "texts = text.split(\".\")\n",
    "\n",
    "# 공백과 줄바꿈 문자를 삭제합니다.\n",
    "texts = [t.strip(\" \\n\") for t in texts]\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcfc014",
   "metadata": {},
   "source": [
    "- 문장 임베딩하기\n",
    "- 문장 리스트를 코히어 API에 전송하여 각 텍스트에 대한 벡터를 얻습니다.\n",
    "- 코히어 클라이언트의 embed 메서드는 최적의 임베딩을 위해 input_type 매개변수에 입력의 종류를 지정해야 합니다.\n",
    "  - 시멘틱 검색의 경우 쿼리는 \"search_query\"로, 검색 대상 텍스트는 \"search_document\"로 지정해야 합니다.\n",
    "  - 분류나 클러스터링의 경우 각각 \"classification\"과 \"clustering\"으로 지정해야 합니다.\n",
    "  - 이미지를 임베딩하는 경우 \"image\"로 지정해야 합니다.\n",
    "  - embed 메서드가 반환하는 객체의 embeddings 속성은 texts 매개변수에 전달한 텍스트에 대한 임베딩을 저장한 리스트입니다.\n",
    "- embed 메서드의 model 매개변수에 임베딩에 사용할 모델을 지정할 수 있습니다.\n",
    "  - 사용 가능한 전체 모델은 코히어 온라인 문서를 참고하세요\n",
    "  - https://docs.cohere.com/reference/embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6e7bdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1536)\n"
     ]
    }
   ],
   "source": [
    "# 임베딩을 만듭니다.\n",
    "response = co.embed(\n",
    "    texts=texts,\n",
    "    model=\"embed-v4.0\",\n",
    "    input_type=\"search_document\",\n",
    "    embedding_types=[\"float\"],\n",
    ").embeddings\n",
    "\n",
    "embeds = np.array(response.float_)\n",
    "print(embeds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d204157f",
   "metadata": {},
   "source": [
    "- 크기가 1536인 벡터가 16개 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c787c3e",
   "metadata": {},
   "source": [
    "- 검색하기 전 검색 인덱스를 구축해야 합니다.\n",
    "- 검색 인덱스는 임베딩을 저장하며 많은 데이터 포인트에서도 빠르게 최근접 이웃을 검색할 수 있도록 최적화되었습니다.\n",
    "- FAISS는 페이스북에서 만든 벡터 유사도 기반 검색 라이브러리입니다.\n",
    "  - https://github.com/facebookresearch/faiss\n",
    "  - IndexFlatL2 클래스는 유클리드 거리 기반으로 최근접 이웃을 찾는 기본적인 인덱스를 생성합니다.\n",
    "  - 벡터를 추가하는 add() 메서드와 벡터를 검색하는 search() 메서드는 모두 32비트 부동소수점 실수를 기대합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd360759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "dim = embeds.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(np.float32(embeds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138365d0",
   "metadata": {},
   "source": [
    "- 인덱스 검색하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ba131af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, number_of_results=3):\n",
    "    # 쿼리 임베딩을 만듭니다.\n",
    "    query_embed = co.embed(\n",
    "        texts=[query],\n",
    "        model=\"embed-v4.0\",\n",
    "        input_type=\"search_query\",\n",
    "        embedding_types=[\"float\"],\n",
    "    ).embeddings.float_[0]\n",
    "\n",
    "    # 최근접 이웃을 추출합니다.\n",
    "    distances, similar_item_ids = index.search(\n",
    "        np.float32([query_embed]), number_of_results\n",
    "    )\n",
    "\n",
    "    # 데이터프레임을 사용해 출력을 준비합니다.\n",
    "    texts_np = np.array(\n",
    "        texts\n",
    "    )  # 인덱싱을 쉽게 하기 위해 텍스트 리스트를 넘파이 배열로 변환합니다.\n",
    "    results = pd.DataFrame(\n",
    "        data={\"텍스트\": texts_np[similar_item_ids[0]], \"거리\": distances[0]}\n",
    "    )\n",
    "\n",
    "    # 결과를 출력하고 반환합니다.\n",
    "    print(f\"쿼리: '{query}'\\n최근접 이웃:\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16c7131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: '영화를 어디서 볼 수 있나요?'\n",
      "최근접 이웃:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>텍스트</th>\n",
       "      <th>거리</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>영화 인터스텔라는 2014년 10월 26일 TCL 차이니즈 극장에서 시사회를 가진 ...</td>\n",
       "      <td>1.025083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>미국에서는 처음에는 필름으로 개봉되었고, 이후 디지털 영사기를 사용하는 극장으로 확...</td>\n",
       "      <td>1.089149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이 영화는 상업적으로 큰 성공을 거두어 개봉 첫 주에 전 세계적으로 6억 8100만...</td>\n",
       "      <td>1.241750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 텍스트        거리\n",
       "0  영화 인터스텔라는 2014년 10월 26일 TCL 차이니즈 극장에서 시사회를 가진 ...  1.025083\n",
       "1  미국에서는 처음에는 필름으로 개봉되었고, 이후 디지털 영사기를 사용하는 극장으로 확...  1.089149\n",
       "2  이 영화는 상업적으로 큰 성공을 거두어 개봉 첫 주에 전 세계적으로 6억 8100만...  1.241750"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"영화를 어디서 볼 수 있나요?\"\n",
    "results = search(query)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24079316",
   "metadata": {},
   "source": [
    "- 키워드 검색 함수를 정의해 확인할 수 있습니다.\n",
    "- 대표적인 어휘 검색 방법인 BM25 알고리즘을 사용하겠습니다.\n",
    "- 코히어 가이드 노트북 : https://github.com/cohere-ai/cohere-developer-experience/blob/main/notebooks/guides/rerank-demo.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aee6b774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질의어 토큰: ['맛있', '사과', '여행']\n",
      "\n",
      "문서 1: 맛있는 사과가 나무에 열려 있습니다.\n",
      "BM25 점수: 5.4558\n",
      "------------------------------\n",
      "문서 2: 기차를 타고 서울에서 부산까지 여행을 갑니다.\n",
      "BM25 점수: 4.9186\n",
      "------------------------------\n",
      "문서 3: 사과 나무 아래에서 기차 소리를 듣습니다.\n",
      "BM25 점수: 4.3583\n",
      "------------------------------\n",
      "문서 4: 오늘 점심은 맛있는 비빔밥을 먹었습니다.\n",
      "BM25 점수: 4.3583\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantization is not supported for ArchType::neon. Fall back to non-quantized model.\n"
     ]
    }
   ],
   "source": [
    "# 한글 BM25 알고리즘을 사용한 키워드 검색 예제\n",
    "\n",
    "from kiwipiepy import Kiwi\n",
    "from rank_bm25 import BM25Plus  # Okapi 대신 Plus 사용 (문서양이 적을 경우 사용)\n",
    "\n",
    "kiwi = Kiwi()\n",
    "\n",
    "\n",
    "# 2. 형태소 분석 함수 정의 (명사, 동사, 형용사 등 의미 있는 품사만 추출)\n",
    "def tokenize_korean(text):\n",
    "    # Kiwi를 통해 형태소 분석\n",
    "    tokens = kiwi.tokenize(text)\n",
    "    # 일반명사(NNG), 고유명사(NNP), 동사(VV), 형용사(VA) 등 주요 키워드만 필터링\n",
    "    return [t.form for t in tokens if t.tag in [\"NNG\", \"NNP\", \"VV\", \"VA\"]]\n",
    "\n",
    "\n",
    "corpus = [\n",
    "    \"맛있는 사과가 나무에 열려 있습니다.\",\n",
    "    \"기차를 타고 서울에서 부산까지 여행을 갑니다.\",\n",
    "    \"사과 나무 아래에서 기차 소리를 듣습니다.\",\n",
    "    \"오늘 점심은 맛있는 비빔밥을 먹었습니다.\",\n",
    "]\n",
    "\n",
    "tokenized_corpus = [tokenize_korean(doc) for doc in corpus]\n",
    "\n",
    "# BM25Plus 모델 사용\n",
    "bm25 = BM25Plus(tokenized_corpus)\n",
    "\n",
    "query = \"맛있는 사과 여행\"\n",
    "tokenized_query = tokenize_korean(query)\n",
    "\n",
    "doc_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "print(f\"질의어 토큰: {tokenized_query}\\n\")\n",
    "for i, score in enumerate(doc_scores):\n",
    "    print(f\"문서 {i + 1}: {corpus[i]}\")\n",
    "    print(f\"BM25 점수: {score:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d12aabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantization is not supported for ArchType::neon. Fall back to non-quantized model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질의어: 맛있는 사과 여행\n",
      "------------------------------\n",
      "문서 1: 맛있는 사과가 나무에 열려 있습니다.\n",
      "BM25 점수: 0.0000\n",
      "------------------------------\n",
      "문서 2: 기차를 타고 서울에서 부산까지 여행을 갑니다.\n",
      "BM25 점수: 0.7773\n",
      "------------------------------\n",
      "문서 3: 사과 나무 아래에서 기차 소리를 듣습니다.\n",
      "BM25 점수: 0.0000\n",
      "------------------------------\n",
      "문서 4: 오늘 점심은 맛있는 비빔밥을 먹었습니다.\n",
      "BM25 점수: 0.0000\n",
      "------------------------------\n",
      "최종 추천 문서: 기차를 타고 서울에서 부산까지 여행을 갑니다.\n"
     ]
    }
   ],
   "source": [
    "# 문서양이 많을 때는 이것을 사용해도 됨\n",
    "\n",
    "from kiwipiepy import Kiwi\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# 1. Kiwi 초기화\n",
    "kiwi = Kiwi()\n",
    "\n",
    "\n",
    "# 2. 형태소 분석 함수 정의 (명사, 동사, 형용사 등 의미 있는 품사만 추출)\n",
    "def tokenize_korean(text):\n",
    "    # Kiwi를 통해 형태소 분석\n",
    "    tokens = kiwi.tokenize(text)\n",
    "    # 일반명사(NNG), 고유명사(NNP), 동사(VV), 형용사(VA) 등 주요 키워드만 필터링\n",
    "    return [t.form for t in tokens if t.tag in [\"NNG\", \"NNP\", \"VV\", \"VA\"]]\n",
    "\n",
    "\n",
    "# 3. 샘플 데이터 (문서 리스트)\n",
    "corpus = [\n",
    "    \"맛있는 사과가 나무에 열려 있습니다.\",\n",
    "    \"기차를 타고 서울에서 부산까지 여행을 갑니다.\",\n",
    "    \"사과 나무 아래에서 기차 소리를 듣습니다.\",\n",
    "    \"오늘 점심은 맛있는 비빔밥을 먹었습니다.\",\n",
    "]\n",
    "\n",
    "# 4. 문서 토큰화\n",
    "tokenized_corpus = [tokenize_korean(doc) for doc in corpus]\n",
    "\n",
    "# 5. BM25 모델 생성\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# 6. 질의어 설정 및 분석\n",
    "query = \"맛있는 사과 여행\"\n",
    "tokenized_query = tokenize_korean(query)\n",
    "\n",
    "# 7. 점수 계산 및 결과 출력\n",
    "doc_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "print(f\"질의어: {query}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for i, score in enumerate(doc_scores):\n",
    "    print(f\"문서 {i + 1}: {corpus[i]}\")\n",
    "    print(f\"BM25 점수: {score:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# 가장 점수가 높은 문서 추출\n",
    "top_n = bm25.get_top_n(tokenized_query, corpus, n=1)\n",
    "print(f\"최종 추천 문서: {top_n[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9679facc",
   "metadata": {},
   "source": [
    "- BM25는 TF-IDF 알고리즘을 개선한 텍스트 랭킹 및 검색 알고리즘입니다.\n",
    "- BM250kapi 클래스에 각 문서를 토큰으로 분할한 리스트를 전달한 후 get_scores() 메서드를 사용해 쿼리와의 유사도 점수를 얻습니다.\n",
    "- https://en.wikipedia.org/wiki/Okapi_BM25\n",
    "- https://github.com/dorianbrown/rank_bm25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요건 영어 일때..\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import string\n",
    "\n",
    "\n",
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.lower().split():\n",
    "        token = token.strip(string.punctuation)  # 구두점 제거\n",
    "        if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
    "            tokenized_doc.append(token)\n",
    "    return tokenized_doc\n",
    "\n",
    "\n",
    "tokenized_corpus = []\n",
    "for passage in tqdm(texts):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "\n",
    "def keyword_search(query, top_k=3, num_candidates=15):\n",
    "    print(\"입력 질문:\", query)\n",
    "\n",
    "    ##### BM25 검색 (어휘 검색) #####\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{\"corpus_id\": idx, \"score\": bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    print(\"탑-3 어휘 검색 (BM25) 결과\")\n",
    "    for hit in bm25_hits[:top_k]:\n",
    "        print(\n",
    "            \"\\t{:.3f}\\t{}\".format(\n",
    "                hit[\"score\"], texts[hit[\"corpus_id\"]].replace(\"\\n\", \" \")\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1241ce49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 565.31it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus = []\n",
    "for passage in tqdm(texts):\n",
    "    tokenized_corpus.append(tokenize_korean(passage))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "\n",
    "def keyword_search(query, top_k=3, num_candidates=15):\n",
    "    print(\"입력 질문:\", query)\n",
    "\n",
    "    ##### BM25 검색 (어휘 검색) #####\n",
    "    bm25_scores = bm25.get_scores(tokenize_korean(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{\"corpus_id\": idx, \"score\": bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    print(\"탑-3 어휘 검색 (BM25) 결과\")\n",
    "    for hit in bm25_hits[:top_k]:\n",
    "        print(\n",
    "            \"\\t{:.3f}\\t{}\".format(\n",
    "                hit[\"score\"], texts[hit[\"corpus_id\"]].replace(\"\\n\", \" \")\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d5cf331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 질문: 영화를 어디서 볼 수 있나요?\n",
      "탑-3 어휘 검색 (BM25) 결과\n",
      "\t0.511\t이 영화는 린다 옵스트가 사망하기 전 프로듀서로서 참여한 마지막 작품입니다\n",
      "\t0.468\t인터스텔라는 크리스토퍼 놀란이 감독하고 그의 형제인 조너선 놀란과 공동으로 각본을 쓴 2014년의 대작 SF 영화입니다\n",
      "\t0.449\t이 영화의 시나리오는 조너선이 2007년에 개발한 각본에서 시작되었으며, 원래 스티븐 스필버그가 감독을 맡을 예정이었습니다\n"
     ]
    }
   ],
   "source": [
    "keyword_search(\"영화를 어디서 볼 수 있나요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3fb1bf",
   "metadata": {},
   "source": [
    "- 쿼리에 있는 영화가 포함되었지만 질문에 대한 답이 아닙니다.\n",
    "- 리랭커를 추가하여 검색 시스템을 어떻게 개선할 수 있는지 알아보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053bc3c4",
   "metadata": {},
   "source": [
    "### 밀집 검색의 단점\n",
    "\n",
    "- 텍스트에 답이 포함되어 있지 않을때..\n",
    "  - 한가지 해결방법은 임계 수준, 관련성에 대한 최대 거리를 지정하는 것입니다.\n",
    "- 많은 시스템이 사용자에게 가능한 최선의 정보를 제공하고 관련있는지에 대한 판단은 사용자에게 맡깁니다.\n",
    "- 사용자가 결과를 만족했는지 정보를 모아 차후 검색 시스템을 향상시킬수 있습니다.\n",
    "- 또 다른 경우는 사용자가 특정 구절과 정확하게 일치하는 결과를 얻고 싶을 때입니다.\n",
    "  - 키워드 매칭이 필요한 경우\n",
    "  - 이 때문에 밀집 검색에만 의존하지 않고 시멘틱 검색과 키워드 검색을 포함하는 하이브리드 검색이 권장됩니다.\n",
    "- 밀집 검색 시스템은 훈련된 도메인 이외에 도메인에서 잘 동작하지 않습니다.\n",
    "  - 예를들어 인터넷과 위키백과 데이터에서 밀집 검색 모델을 훈련하고 법률 문서에 적용한다면 모델이 이 법률 도메인에서 잘 동작하지 않을것입니다.\n",
    "- 사용자가 어떤 정보를 요청하는 쿼리를 전달했을 때 각 문장이 정보의 일부를 담고 있는 경우입니다.\n",
    "  - 질문의 답변이 여러 문장에 걸쳐 있다면 어떻게 될까요?\n",
    "  - 텍스트를 청크로 나누는 최상의 방법은 무엇일까요?\n",
    "  - 애초에 텍스트를 청크로 나누는 이유는 무엇인가요?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204bb79f",
   "metadata": {},
   "source": [
    "### 텍스트를 청크로 나누기\n",
    "\n",
    "- 트랜스포머 언어 모델의 한가지 제약은 제한된 문맥 크기입니다.\n",
    "  - 모델이 지원하는 단어 또는 토큰 수보다 더 긴 텍스트를 주입할 수 없다는 의미입니다.\n",
    "  - 긴 텍스트를 어떻게 임베딩할 수 있을까요?\n",
    "  - 문서당 벡터 하나를 인덱싱하거나 문서마다 여러 개의 벡터를 인덱싱하는 것입니다.\n",
    "\n",
    "#### 문서당 하나의 벡터\n",
    "\n",
    "- 전체 문서를 하나의 벡터로 표현합니다.\n",
    "  - 문서에서 대표적인 부분만 임베딩하고 나머지 텍스트는 무시합니다.\n",
    "    - 제목이나 문서의 시작 부분만 임베딩할 수 있습니다.\n",
    "    - 빠르게 데모를 만드는 데 유용하지만 인덱싱되지 않은 정보가 많아 검색되지 않을 수 있습니다.\n",
    "    - 시작 부분에 문서의 핵심 내용이 있는 경우 잘 동작할 수 있습니다.\n",
    "    - 하지만 많은 정보가 인덱싱되지 않아 검색할 수 없기 때문에 실제 시스템에서 최상의 방법은 아닙니다.\n",
    "  - 문서를 청크로 나누고 해당 청크를 임베딩한 다음 하나의 벡터로 집계합니다.\n",
    "    - 집계하는 일반적인 방법은 이런 벡터를 평균하는 것입니다.\n",
    "    - 벡터가 많이 압축되어 문서에 있는 내용을 많이 잃는다는 단점이 있습니다.\n",
    "- 일부 요구사항을 만족할 수 있지만 전부는 아닙니다.\n",
    "- 대부분의 경우 검색은 문서에 포함된 특정 정보를 원합니다.\n",
    "- 해당 개념이 자체적인 벡터로 표현될 때 더 잘 감지됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca4f4ad",
   "metadata": {},
   "source": [
    "### 문서당 여러 개의 벡터\n",
    "\n",
    "- 문서를 더 작은 단위인 청크로 나누고 이런 청크를 임베딩합니다.\n",
    "- 검색 인덱스는 전체 문서의 인덱스가 아니라 청크 임베딩의 인덱스가 됩니다.\n",
    "  - 문자분할, 토큰분할, 토큰분할 (1개 토큰을 겹침)\n",
    "- 청크 방법은 텍스트 전체를 포괄하고 벡터가 텍스트 안에 있는 개별 개념을 포착하기 때문에 더 낫습니다.\n",
    "- 표현력이 더 좋은 검색 인덱스가 만들어집니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10baeb80",
   "metadata": {},
   "source": [
    "- 긴 문서를 청크로 나누는 가장 좋은 방법은 텍스트 유형과 시스템에서 예상하는 쿼리에 따라 다릅니다.\n",
    "  - 각 문장이 하나의 청크입니다. 너무 세분화되어 벡터가 문맥을 충분히 포착하지 못할 수 있습니다.\n",
    "  - 각 문단이 하나의 청크입니다. 짧은 문단으로 구성된 경우 잘 맞습니다. 그렇지 않다면 3~8개의 문장마다 하나의 청크로 만들수 있습니다.\n",
    "  - 일부 청크는 주변 텍스트에서 많은 의미를 유추합니다. 따라서 다음과 같은 방식으로 일부 문맥을 통합할 수 있습니다.\n",
    "    - 문서 제목을 청크에 추가합니다.\n",
    "    - 청크 앞뒤에 있는 일부 텍스트를 추가합니다. 청크가 겹칠수 있어 주변 텍스트가 인접한 청크에 나타나게 됩니다.\n",
    "- 이 분야가 발전하면서 더 많은 청크 분할 전략이 등장할 것입니다. 일부는 LLM을 사용하여 동적으로 텍스트를 의미 있는 청크로 분할할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb62c900",
   "metadata": {},
   "source": [
    "### 최근업 이웃 검색 vs 벡터 데이터베이스\n",
    "\n",
    "- 쿼리를 임베딩한 후 텍스트 아카이브에서 쿼리 벡터와 가장 가까운 벡터를 찾아야 합니다.\n",
    "- 최근접 이웃을 찾는 가장 간단한 방법은 쿼리와 각 문서 사이의 거리를 계산하는 것입니다.\n",
    "- 넘파이로 쉽게 계산할 수 있으며, 벡터가 수천, 수만개라면 합리적인 접근방법입니다.\n",
    "- 수백만개의 벡터로 확장될때 Annoy나 FAISS 같은 근사 최근접 이웃 검색라이브러리를 사용하는 것입니다.\n",
    "- 방대한 인덱스에서 밀리초단위로 결과를 검색할 수 있고 GPU를 활용하거나 매우 큰 인덱스를 위해 여러 머신으로 구성된 클러스터를 적용해 성능 향상시킬수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc2e96d",
   "metadata": {},
   "source": [
    "- Weaviate나 Pinecone 같은 벡터 데이터베이스 입니다.\n",
    "- 벡터 데이터베이스를 사용하면 인덱스를 재구축할 필요 없이 벡터를 추가하거나 삭제할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb897e4",
   "metadata": {},
   "source": [
    "#### 밀집 검색을 위해 임베딩 모델 미세 튜닝하기\n",
    "\n",
    "- 검색도 단순한 토큰 임베딩이 아니라 텍스트 임베딩을 최적화할 필요가 있습니다.\n",
    "- 미세 튜닝 과정에는 쿼리 및 이와 관련된 결과로 구성된 훈련 데이터가 사용됩니다.\n",
    "- 데이터 셋 샘플문장 : 영화 인터스텔라는 2014년 10월 26일 TCL 차이니즈 극장에서 시사회를 가진 후, 11월 5일 미국에서, 11월 7일 영국에서 극장 개봉했습니다.\n",
    "  - 관련있는 쿼리1 : 인터스텔라 영화는 어디에서 시사회를 가졌나요?\n",
    "  - 관련있는 쿼리2 : 인터스텔라 영화는 영국에서 언제 개봉했나요?\n",
    "- 미세 튜닝 과정은 이런 쿼리의 임베딩이 결과 문장의 임베딩에 가깝게 만드는 것이 목표입니다.\n",
    "- 이 문장과 관련이 없는 네거티브 쿼리 샘플도 필요합니다.\n",
    "  - 관련없는 쿼리 : 인터스텔라 캐스팅\n",
    "- 이런 샘플을 사용해 3개의 쌍을 준비합니다.\n",
    "  - 2개의 포지티브 샘플 쌍과 1개의 네거티브 샘플 쌍입니다.\n",
    "  - 미세 튜닝 전에 세 개의 쿼리가 모두 결과 문서로부터 같은 거리만큼 떨어져 있다고 가정합니다.\n",
    "  - 3쿼리가 모두 인터스텔라에 관해 말하기 때문에 크게 과장된것은 아닙니다.\n",
    "  - 미세 튜닝 단계는 관련 있는 쿼리를 문서에 더 가깝게 만들고 동시에 관련 없는 쿼리는 문서에서 멀어지게 만듭니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3d97ae",
   "metadata": {},
   "source": [
    "### 리랭킹\n",
    "\n",
    "- 검색 시스템의 마지막 단계에 관련성을 기반으로 검색 결과 순서를 조정합니다.\n",
    "- 리랭커는 검색 파이프라인 일부로 동작, 적은 개수의 검색 결과와 순서를 관련성에 따라 재정렬하는 것이 목표입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f711e9",
   "metadata": {},
   "source": [
    "#### 리랭킹 예제\n",
    "\n",
    "- https://docs.cohere.com/reference/rerank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "21cb5c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[V2RerankResponseResultsItem(index=4, relevance_score=0.8167574),\n",
       " V2RerankResponseResultsItem(index=3, relevance_score=0.7103069),\n",
       " V2RerankResponseResultsItem(index=1, relevance_score=0.70383453)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"과학은 정확했었나요?\"\n",
    "results = co.rerank(query=query, documents=texts, model=\"rerank-v4.0-pro\", top_n=3)\n",
    "results.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "210eb29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8167574 이론 물리학자 킵 손은 이 영화의 총괄 프로듀서이자 과학 자문으로 참여했으며, 관련 서적인 《인터스텔라의 과학》을 집필했습니다\n",
      "1 0.7103069 이 영화의 시나리오는 조너선이 2007년에 개발한 각본에서 시작되었으며, 원래 스티븐 스필버그가 감독을 맡을 예정이었습니다\n",
      "2 0.70383453 매튜 맥코너히, 앤 해서웨이, 제시카 채스테인, 빌 어윈, 엘렌 버스틴, 마이클 케인 등 앙상블 캐스트가 출연합니다\n"
     ]
    }
   ],
   "source": [
    "for idx, result in enumerate(results.results):\n",
    "    print(idx, result.relevance_score, texts[result.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2023174",
   "metadata": {},
   "source": [
    "- 간단한 예제에서 15개 문서를 모두 전달했습니다.\n",
    "- 수천, 수백만개 -> 수백 또는 수천개 정도의 짧은 목록을 만들어 리랭커에 전달해야 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb29709b",
   "metadata": {},
   "source": [
    "- 첫번째 단계의 검색은 키워드 검색, 밀집 검색 또는 두 방식을 사용하는 하이브리드 검색일수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa775f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_and_reranking_search(query, top_k=3, num_candidates=15):\n",
    "    print(\"입력 질문:\", query)\n",
    "\n",
    "    ##### BM25 검색 (어휘 검색) #####\n",
    "    bm25_scores = bm25.get_scores(tokenize_korean(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{\"corpus_id\": idx, \"score\": bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    print(\"탑-3 어휘 검색 (BM25) 결과\")\n",
    "    for hit in bm25_hits[:top_k]:\n",
    "        print(\n",
    "            \"\\t{:.3f}\\t{}\".format(\n",
    "                hit[\"score\"], texts[hit[\"corpus_id\"]].replace(\"\\n\", \" \")\n",
    "            )\n",
    "        )\n",
    "\n",
    "    ##### 리랭킹 #####\n",
    "    docs = [texts[hit[\"corpus_id\"]] for hit in bm25_hits]\n",
    "    print(f\"\\n리랭크으로 얻은 탑-3 결과 ({len(bm25_hits)}) 개의 BM25 결과를 재조정함\")\n",
    "    rerank_results = co.rerank(\n",
    "        query=query,\n",
    "        documents=docs,\n",
    "        model=\"rerank-v4.0-pro\",\n",
    "        top_n=top_k,\n",
    "    ).results\n",
    "\n",
    "    for idx, result in enumerate(rerank_results):\n",
    "        print(\n",
    "            \"\\t{:.3f}\\t{}\".format(\n",
    "                result.relevance_score, docs[result.index].replace(\"\\n\", \" \")\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3875845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 질문: 영화는 어떤 내용인가요?\n",
      "탑-3 어휘 검색 (BM25) 결과\n",
      "\t0.511\t이 영화는 린다 옵스트가 사망하기 전 프로듀서로서 참여한 마지막 작품입니다\n",
      "\t0.468\t인터스텔라는 크리스토퍼 놀란이 감독하고 그의 형제인 조너선 놀란과 공동으로 각본을 쓴 2014년의 대작 SF 영화입니다\n",
      "\t0.449\t이 영화의 시나리오는 조너선이 2007년에 개발한 각본에서 시작되었으며, 원래 스티븐 스필버그가 감독을 맡을 예정이었습니다\n",
      "\n",
      "리랭크으로 얻은 탑-3 결과 (15) 개의 BM25 결과를 재조정함\n",
      "\t0.952\t지구가 재앙적인 병충해와 기근으로 고통받는 디스토피아적 미래를 배경으로, 인류를 위한 새로운 보금자리를 찾아 우주를 여행하는 우주 비행사들의 이야기를 담고 있습니다\n",
      "\t0.915\t인터스텔라는 크리스토퍼 놀란이 감독하고 그의 형제인 조너선 놀란과 공동으로 각본을 쓴 2014년의 대작 SF 영화입니다\n",
      "\t0.903\t이 영화의 시나리오는 조너선이 2007년에 개발한 각본에서 시작되었으며, 원래 스티븐 스필버그가 감독을 맡을 예정이었습니다\n"
     ]
    }
   ],
   "source": [
    "keyword_and_reranking_search(\"영화는 어떤 내용인가요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30adb088",
   "metadata": {},
   "source": [
    "- 이는 리랭킹의 효과를 보이기 위한 아주 간단한 예제이지만 실제로 이런 파이프라인은 검색 품질을 크게 향상시킵니다.\n",
    "- https://cohere.com/blog/rerank-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed831501",
   "metadata": {},
   "source": [
    "### 센텐스 트랜스포머를 사용한 오픈 소스 검색과 리랭킹\n",
    "\n",
    "- 검색과 리랭킹을 로컬 머신에 구축하고 싶다면 센텐스 트랜스포머 라이브러리를 사용할 수 있습니다.\n",
    "- https://www.sbert.net/\n",
    "- https://www.sbert.net/examples/sentence_transformer/applications/retrieve_rerank/README.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802fea8",
   "metadata": {},
   "source": [
    "### 리랭킹 모델의 작동 방식\n",
    "\n",
    "- 크로스 인코더로 동작하는 LLM에게 쿼리와 결과를 전달하는 것입니다.\n",
    "- 모델에게 쿼리와 후보 결과를 동시에 전달하여 모델이 두 텍스트를 모두 본 다음 관련성 점수를 할당한다는 의미입니다.\n",
    "- 모든 문서가 하나의 배치로 동시에 처리되지만 각각의 문서가 독립적으로 쿼리에 대해 평가됩니다.\n",
    "- 이 점수가 새로운 순위를 결정합니다.\n",
    "- https://arxiv.org/abs/1910.14424\n",
    "- monoBERT라고 불립니다.\n",
    "- 관련성 점수로 검색 시스템을 구성하는 것은 기본적으로 분류 문제로 귀결됩니다.\n",
    "- 입력이 주어지면 모델은 0~1 사이의 점수를 출력합니다.\n",
    "- 0은 관련 없음을 나타내고 1은 관련이 매우 높음을 의미합니다.\n",
    "- https://arxiv.org/abs/2010.06467\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_cpp_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
